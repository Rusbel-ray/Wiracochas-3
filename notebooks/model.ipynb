{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VoZ0a-mISssX"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "# Cargar el dataset limpio\n",
        "data = pd.read_csv('cleaned_dataset.csv')\n",
        "\n",
        "# Separar variables independientes (X) y la variable dependiente (y)\n",
        "X = data.drop(columns=['Desercion'])\n",
        "y = data['Desercion']\n",
        "\n",
        "# Dividir los datos en entrenamiento y prueba\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Inicializar una lista para almacenar los resultados\n",
        "results = []\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo 1: Regresión Logística\n",
        "logreg = LogisticRegression(max_iter=1000)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred_logreg = logreg.predict(X_test)\n",
        "results.append(['Regresión Logística', accuracy_score(y_test, y_pred_logreg)])\n",
        "\n",
        "# Evaluación del modelo de Regresión Logística\n",
        "print(\"Evaluación de Regresión Logística:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
        "print(confusion_matrix(y_test, y_pred_logreg))\n",
        "print(classification_report(y_test, y_pred_logreg))\n",
        "\n",
        "# Modelo 2: Árbol de Decisión\n",
        "tree = DecisionTreeClassifier()\n",
        "tree.fit(X_train, y_train)\n",
        "y_pred_tree = tree.predict(X_test)\n",
        "results.append(['Árbol de Decisión', accuracy_score(y_test, y_pred_tree)])\n",
        "\n",
        "# Evaluación del modelo de Árbol de Decisión\n",
        "print(\"Evaluación de Árbol de Decisión:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_tree))\n",
        "print(confusion_matrix(y_test, y_pred_tree))\n",
        "print(classification_report(y_test, y_pred_tree))\n",
        "\n",
        "# Modelo 3: Random Forest\n",
        "rf = RandomForestClassifier()\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred_rf = rf.predict(X_test)\n",
        "results.append(['Random Forest', accuracy_score(y_test, y_pred_rf)])\n",
        "\n",
        "# Evaluación del modelo de Random Forest\n",
        "print(\"Evaluación de Random Forest:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
        "print(confusion_matrix(y_test, y_pred_rf))\n",
        "print(classification_report(y_test, y_pred_rf))\n",
        "\n",
        "# Modelo 4: K-Nearest Neighbors (KNN)\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "results.append(['K-Nearest Neighbors', accuracy_score(y_test, y_pred_knn)])\n",
        "\n",
        "# Evaluación del modelo KNN\n",
        "print(\"Evaluación de K-Nearest Neighbors:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_knn))\n",
        "print(confusion_matrix(y_test, y_pred_knn))\n",
        "print(classification_report(y_test, y_pred_knn))\n",
        "\n",
        "# Modelo 5: Support Vector Machine (SVM)\n",
        "svm = SVC()\n",
        "svm.fit(X_train, y_train)\n",
        "y_pred_svm = svm.predict(X_test)\n",
        "results.append(['Support Vector Machine', accuracy_score(y_test, y_pred_svm)])\n",
        "\n",
        "# Evaluación del modelo SVM\n",
        "print(\"Evaluación de Support Vector Machine:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
        "print(confusion_matrix(y_test, y_pred_svm))\n",
        "print(classification_report(y_test, y_pred_svm))\n",
        "\n",
        "# Modelo 6: Gradient Boosting\n",
        "gb = GradientBoostingClassifier()\n",
        "gb.fit(X_train, y_train)\n",
        "y_pred_gb = gb.predict(X_test)\n",
        "results.append(['Gradient Boosting', accuracy_score(y_test, y_pred_gb)])\n",
        "\n",
        "# Evaluación del modelo Gradient Boosting\n",
        "print(\"Evaluación de Gradient Boosting:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
        "print(confusion_matrix(y_test, y_pred_gb))\n",
        "print(classification_report(y_test, y_pred_gb))\n",
        "\n",
        "# Guardar resultados de todos los modelos en un DataFrame\n",
        "results_df = pd.DataFrame(results, columns=['Modelo', 'Accuracy'])\n",
        "\n",
        "print(\"Comparativa de modelos:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ju-fwhXAdc3e",
        "outputId": "04adc319-1616-4cce-9558-535aee39ec77"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluación de Regresión Logística:\n",
            "Accuracy: 0.7777777777777778\n",
            "[[130  59]\n",
            " [ 41 220]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.69      0.72       189\n",
            "           1       0.79      0.84      0.81       261\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.77      0.77      0.77       450\n",
            "weighted avg       0.78      0.78      0.78       450\n",
            "\n",
            "Evaluación de Árbol de Decisión:\n",
            "Accuracy: 0.7844444444444445\n",
            "[[132  57]\n",
            " [ 40 221]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.70      0.73       189\n",
            "           1       0.79      0.85      0.82       261\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.78      0.77      0.78       450\n",
            "weighted avg       0.78      0.78      0.78       450\n",
            "\n",
            "Evaluación de Random Forest:\n",
            "Accuracy: 0.8444444444444444\n",
            "[[132  57]\n",
            " [ 13 248]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.70      0.79       189\n",
            "           1       0.81      0.95      0.88       261\n",
            "\n",
            "    accuracy                           0.84       450\n",
            "   macro avg       0.86      0.82      0.83       450\n",
            "weighted avg       0.85      0.84      0.84       450\n",
            "\n",
            "Evaluación de K-Nearest Neighbors:\n",
            "Accuracy: 0.6666666666666666\n",
            "[[112  77]\n",
            " [ 73 188]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.61      0.59      0.60       189\n",
            "           1       0.71      0.72      0.71       261\n",
            "\n",
            "    accuracy                           0.67       450\n",
            "   macro avg       0.66      0.66      0.66       450\n",
            "weighted avg       0.67      0.67      0.67       450\n",
            "\n",
            "Evaluación de Support Vector Machine:\n",
            "Accuracy: 0.7755555555555556\n",
            "[[118  71]\n",
            " [ 30 231]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.62      0.70       189\n",
            "           1       0.76      0.89      0.82       261\n",
            "\n",
            "    accuracy                           0.78       450\n",
            "   macro avg       0.78      0.75      0.76       450\n",
            "weighted avg       0.78      0.78      0.77       450\n",
            "\n",
            "Evaluación de Gradient Boosting:\n",
            "Accuracy: 0.82\n",
            "[[131  58]\n",
            " [ 23 238]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.69      0.76       189\n",
            "           1       0.80      0.91      0.85       261\n",
            "\n",
            "    accuracy                           0.82       450\n",
            "   macro avg       0.83      0.80      0.81       450\n",
            "weighted avg       0.82      0.82      0.82       450\n",
            "\n",
            "Comparativa de modelos:\n",
            "                   Modelo  Accuracy\n",
            "0     Regresión Logística  0.777778\n",
            "1       Árbol de Decisión  0.784444\n",
            "2           Random Forest  0.844444\n",
            "3     K-Nearest Neighbors  0.666667\n",
            "4  Support Vector Machine  0.775556\n",
            "5       Gradient Boosting  0.820000\n"
          ]
        }
      ]
    }
  ]
}